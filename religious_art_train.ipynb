{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "name": "religious_art_train.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "sT7Co96sN8O8",
        "o12l_VDROF97",
        "qYBzgFz45C74",
        "bfdhPhilhnWI",
        "k7eOw7O1cBo2",
        "RGNBJTlrAC3i",
        "XO1BhVwY-8BC",
        "b04KlTeoW0Ya",
        "OOMirTaVWqPb",
        "t2ChjApGWvSx",
        "ENtOyP15ma62"
      ],
      "toc_visible": true,
      "mount_file_id": "1G1LGYoCdXjzmbtcZZoLq76HUAyTaRjJC",
      "authorship_tag": "ABX9TyOgfzY+I4pBE9QVQUTozFbj",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tyanakai/religious_art/blob/main/religious_art_train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hfkOYiO8BSnD"
      },
      "source": [
        "<h1>宗教画テーマの分類　訓練</h1>\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sT7Co96sN8O8"
      },
      "source": [
        "# 1.はじめに\n",
        "本ノートブックの目的は、ProbSpace上で開催された[宗教画テーマの分類](https://comp.probspace.com/competitions/religious_art)のタスクに基づいて、<br>\n",
        "公開されている事前学習されたモデルを訓練し、保存することです。<br>\n",
        "使用するモデルは以下の通りです。\n",
        "\n",
        "*   [EfficientNet-B4, EfficientNet-B7](https://github.com/qubvel/efficientnet)\n",
        "*   [EfficientNetV2-S](https://github.com/google/automl/tree/master/efficientnetv2)\n",
        "\n",
        "尚、colabratory上で、ランタイムのタイプをTPUに設定した状態での実行を想定しています。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o12l_VDROF97"
      },
      "source": [
        "# 2.事前に完了していること\n",
        "*    [religious_art_eda.ipynb](https://github.com/Tyanakai/religious_art/blob/main/religious_art_eda.ipynb)の実行\n",
        "*    上で保存した画像をGoogle Cloud Storageにアップロード\n",
        "\n",
        "<br>\n",
        "今回の訓練では、Google Cloud Storageに保存した画像(jpg形式)を使用して訓練します。<br>\n",
        "事前にreligious_art_eda.ipynbを実行し、保存した(train_image, test_image)フォルダをGoogle Cloud Storageにアップロードしておきます。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "itSzpJd4VTae"
      },
      "source": [
        "# 3.環境準備\n",
        "訓練環境を構築します。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qYBzgFz45C74"
      },
      "source": [
        "## 3.1ライブラリ"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QtL3wc8jey2G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "764aa23c-21f5-46ea-a649-8c4b7311209b"
      },
      "source": [
        "!pip install -q tensorflow-addons\n",
        "!pip install -q efficientnet\n",
        "\n",
        "import datetime\n",
        "import json\n",
        "import os\n",
        "import sys\n",
        "\n",
        "import efficientnet.tfkeras as efn\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras.backend as K\n",
        "import tensorflow_addons as tfa\n",
        "import tensorflow_hub as hub"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 1.1 MB 5.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 50 kB 2.6 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bfdhPhilhnWI"
      },
      "source": [
        "## 3.2 Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hdZQavLchsKz"
      },
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k7eOw7O1cBo2"
      },
      "source": [
        "## 3.3 Google Cloud Storage\n",
        "Google Cloud Storageとの接続の為に、ユーザー認証します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H9oXMr7TcJoW"
      },
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RGNBJTlrAC3i"
      },
      "source": [
        "## 3.4 TPU\n",
        "TPU使用の為の設定を行います。今回はcloud上のデータに対しTPUを使用します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-G3QJuwezry",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2403e8cd-80c9-41e8-b0fb-852722b74838"
      },
      "source": [
        "project_id = 'Google Cloudのproject id'\n",
        "!gcloud config set project {project_id}\n",
        "!gsutil ls\n",
        "\n",
        "try:\n",
        "    tpu_grpc_url = \"grpc://\" + os.environ[\"COLAB_TPU_ADDR\"]\n",
        "    TPU = tf.distribute.cluster_resolver.TPUClusterResolver(tpu_grpc_url)\n",
        "except:\n",
        "    TPU = None\n",
        "    print('INFO: Not connected to a TPU runtime')\n",
        "\n",
        "AUTOTUNE = tf.data.experimental.AUTOTUNE"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Updated property [core/project].\n",
            "gs://colab_test2/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nzl51Yd69RQY"
      },
      "source": [
        "## 3.5 ハイパーパラメータ設定\n",
        "\n",
        "主なパラメーターの説明は下記の通りです。\n",
        "\n",
        "|パラメータ名|説明|\n",
        "|:-|:-|\n",
        "|model|使用する事前学習されたモデル名|\n",
        "|weights|事前学習のタイプ efnの場合'noisy-student', efn-v2の場合'imagenet21k-ft1k'|\n",
        "|-|-|\n",
        "|original_size|画像の原寸。正方形の一辺の長さ|\n",
        "|image_size|tf.data.Dataset形式に変換する際の画像サイズ|\n",
        "|patience|EarlyStoppingのパラメータ。訓練早期終了を延期するepoch数|\n",
        "|stop_monitor|arlyStoppingのパラメータ。訓練早期終了を判定する指標|\n",
        "|best_monitor|ModelCheckpointのパラメータ。保存するmodelの選定指標|\n",
        "|-|-|\n",
        "|num_ops|random augmentを行う際、一度の拡張で適用する手法の数| \n",
        "|magnitude|random augmentを行う際、適用する拡張手法の度合|\n",
        "|-|-|\n",
        "|lr_base|学習率の初期値|\n",
        "|lr_max|学習率の最大値|\n",
        "|lr_min|学習率の最小値|\n",
        "|begining|訓練初期段階で、学習率をlr_baseからlr_maxまで引き上げるまでのepoch数|\n",
        "|ending|学習率がlr_baseに再降下するepoch数|\n",
        "|-|-|\n",
        "|pseudo|準備した擬似ラベルを訓練に使用するか|\n",
        "|exclusive|重複画像を除いたデータを訓練に使用するか|\n",
        "|copy|個数の少ないクラスの訓練データを複製するか|\n",
        "|copy_classes|複製対象とするクラス|\n",
        "|copy_rate|複製の割合。dup_rate=0:対象データを全て複製、dup_rate=1:複製しない|"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jF1mWlKa9QQh"
      },
      "source": [
        "class Config:\n",
        "    model = \"efn_b7\"  #@param [\"efn_b4\",\"efn_b7\",\"efficientnetv2-s\"]\n",
        "    weights = 'noisy-student' #@param ['noisy-student','imagenet21k-ft1k']\n",
        "    base_batch_size = 2 #@param {type:\"raw\"} [1,2,4,8,16]\n",
        "    batch_size = base_batch_size * 8\n",
        "    epochs = 100 #@param {type:\"raw\"}\n",
        "    n_folds = 5\n",
        "    seed = 21 #@param\n",
        "\n",
        "    original_size = 224\n",
        "    # v2-s:384, v2-m:480\n",
        "    image_size = 600    #@param {type:\"raw\"} [224,240,260,300,380,456,528,600,384,480]\n",
        "    n_classes = 13\n",
        "    patience =  20 #@param\n",
        "    stop_monitor= \"val_loss\" #@param [\"val_loss\", \"val_accuracy\"]\n",
        "    best_monitor = \"val_accuracy\" #@param [\"val_loss\", \"val_accuracy\"]\n",
        "\n",
        "    num_ops = 10 #@param {type:\"slider\", min:0, max:15, step:1}\n",
        "    magnitude = 5 #@param {type:\"slider\", min:0, max:10, step:1}\n",
        "\n",
        "    lr_base = 1e-5\n",
        "    lr_max = 7 * 1e-4\n",
        "    lr_min = 1e-10\n",
        "    begining = 10\n",
        "    ending = 70\n",
        "\n",
        "    pseudo = False #@param {\"type\":\"boolean\"}\n",
        "    pseudo_file = \"pseudo_soft.csv\" #@param\n",
        "    exclusive = True #@param {\"type\":\"boolean\"}\n",
        "    copy = True #@param {\"type\":\"boolean\"}\n",
        "    copy_classes = [7, 8, 10, 12] #@param\n",
        "    copy_rate = 0.7\n",
        "\n",
        "    debug = True #@param {\"type\":\"boolean\"}\n",
        "\n",
        "if Config.debug:\n",
        "    Config.epochs = 2\n",
        "    Config.n_folds = 2\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u4jiyD6L9_Aj"
      },
      "source": [
        "## 3.6 path\n",
        "pathを設定しfolderを作成します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EAbhAXnG9-w0"
      },
      "source": [
        "DRIVE = \"/content/drive/MyDrive/portforio/religious_art\"\n",
        "GS = \"gs://colab_test2/\" # Google Cloud Storage \n",
        "\n",
        "INPUT = os.path.join(DRIVE, \"input\")\n",
        "OUTPUT = os.path.join(DRIVE, \"output\")\n",
        "MODEL = os.path.join(DRIVE, \"model\", f\"{Config.model}-{Config.image_size}\")\n",
        "RECORD = os.path.join(DRIVE, \"model\", \"record\")\n",
        "SUBMIT = os.path.join(DRIVE, \"submit\")\n",
        "PROB = os.path.join(DRIVE, \"prob\") # 予測確率値(probability)を保存するフォルダ\n",
        "\n",
        "GS_TRAIN = os.path.join(GS, \"train_image\")\n",
        "GS_TEST = os.path.join(GS, \"test_image\")\n",
        "\n",
        "DRIVE_TRAIN = os.path.join(INPUT, \"train_image\")\n",
        "\n",
        "for folder in [INPUT, OUTPUT, MODEL, RECORD, SUBMIT, PROB]:\n",
        "    os.makedirs(folder, exist_ok=True)\n",
        "\n",
        "# efficientnet-v2のdownload元\n",
        "weights_dic = {\"imagenet21k-ft1k\":\"21k-ft1k\",\"imagenet21k\":\"21k\"}\n",
        "hub_url = ('gs://cloud-tpu-checkpoints/efficientnet/v2/hub'\n",
        "           f'/{Config.model}-{weights_dic.get(Config.weights,None)}/feature-vector')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XO1BhVwY-8BC"
      },
      "source": [
        "# 4.データ準備\n",
        "データを処理し、tf.data.Datasetとして取得するための関数やクラスを定義します。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b04KlTeoW0Ya"
      },
      "source": [
        "## 4.1 取得"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q3ogPLWYg48h"
      },
      "source": [
        "def get_train_data():\n",
        "    \"\"\"\n",
        "    訓練データのfilepathのリストと訓練ラベルを取得する。\n",
        "    \"\"\"\n",
        "    labels = np.load(\n",
        "        os.path.join(INPUT, \"christ-train-labels.npz\"))[\"arr_0\"]\n",
        "    labels = pd.get_dummies(labels).values.astype(np.float32)\n",
        "    labels = smooth_label(labels)\n",
        "\n",
        "    file_idx = np.arange(labels.shape[0])\n",
        "    if Config.exclusive:\n",
        "        file_idx = make_exclusive(file_idx)\n",
        "\n",
        "    filepaths = np.array(\n",
        "        [GS_TRAIN + f\"/train_img{i:0>3d}.jpg\" for i in file_idx])\n",
        "          \n",
        "    return filepaths, labels[file_idx]\n",
        "\n",
        "\n",
        "def get_test_data():\n",
        "    test_imgs = np.load(\n",
        "        os.path.join(INPUT, \"christ-test-imgs.npz\"))[\"arr_0\"]\n",
        "    file_idx = np.arange(test_imgs.shape[0])\n",
        "    filepaths = np.array(\n",
        "        [GS_TEST + f\"/test_img{i:0>3d}.jpg\" for i in file_idx])\n",
        "    \n",
        "    return filepaths\n",
        "\n",
        "\n",
        "def concat_pseudo(filepaths, labels):\n",
        "    \"\"\"\n",
        "    擬似ラベルを取得、連結し、ファイルパスを上書きする。\n",
        "    \"\"\"\n",
        "    pseudo_file = pd.read_csv(os.path.join(OUTPUT, Config.pseudo_file), \n",
        "                              index_col=0)\n",
        "    pseudo_idx = pseudo_file.index.value\n",
        "    if Config.exclusive:\n",
        "        pseudo_idx = make_exclusive(pseudo_idx)\n",
        "\n",
        "    labels = np.concatenate([labels, pseudo_file.values], axis=0).astype(np.float32)\n",
        "\n",
        "    pse_filepaths = np.array(\n",
        "        [GS_TEST + f\"/test_img{i:0>3d}.jpg\" for i in pseudo_idx])\n",
        "    filepaths = np.concat([filepaths, pse_filepaths], axis=0)\n",
        "    \n",
        "    return filepaths, labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OOMirTaVWqPb"
      },
      "source": [
        "## 4.2 加工"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PsRPBUSjUAeV"
      },
      "source": [
        "def smooth_label(label, factor=0.1):\n",
        "    \"\"\"\n",
        "    label smoothingを適用する。\n",
        "    \"\"\"\n",
        "    labels = np.array((1 - factor) * label + (factor / label.shape[1]))\n",
        "    return labels.astype(np.float32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40_4L_hJwqUC"
      },
      "source": [
        "def make_exclusive(index_list):\n",
        "    \"\"\"\n",
        "    index_listからdup_idxにあるindexを取り除く\n",
        "    \"\"\"\n",
        "    dup_idx = np.load(os.path.join(OUTPUT, \"dup_idx.npy\"))\n",
        "    exclusive_idx_set = set(idx for idx in index_list) - set(dup_idx)\n",
        "    return np.array(list(exclusive_idx_set))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_4cAY7GT4Kf"
      },
      "source": [
        "def copy_few_data(ids, labels):\n",
        "    \"\"\"\n",
        "    個数の少ないクラスのindexを確率的に複製する。\n",
        "    \"\"\"\n",
        "    class_labels = np.argmax(labels, axis=1)\n",
        "    copy_ids = []\n",
        "    for idx in ids:\n",
        "        rn = np.random.uniform()       \n",
        "        if class_labels[idx] in Config.copy_classes and rn > Config.copy_rate:\n",
        "            copy_ids += [idx, idx]\n",
        "        else:\n",
        "            copy_ids.append(idx)\n",
        "    return np.array(copy_ids)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0bPhSwghdPSP"
      },
      "source": [
        " def skf(x_train, y_train, n_folds=Config.n_folds, random_state=Config.seed):\n",
        "     \"\"\"\n",
        "     訓練データを層化K分割し、リスト化したindexを取得する。\n",
        "     \"\"\"\n",
        "     kf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=random_state)\n",
        "     return list(kf.split(x_train, y_train))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t2ChjApGWvSx"
      },
      "source": [
        "## 4.3 tf.data.Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RFCqPdJNOKGy"
      },
      "source": [
        "class ImageProcessor():\n",
        "    \"\"\"\n",
        "    file pathを受け取り、画像を取得、拡張、tf.data.Dataset形式で出力\n",
        "\n",
        "    Parameters\n",
        "    --------------\n",
        "        num_ops : int\n",
        "            random augmentを行う際、適用する拡張手法の数\n",
        "        magnitude : int\n",
        "            random augmentを行う際、適用する拡張手法の度合\n",
        "        image_size : int\n",
        "            datasetの出力画像サイズ(＝訓練モデルの入力画像サイズ)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, num_ops, magnitude, image_size=Config.image_size):\n",
        "        self.num_ops = num_ops\n",
        "        self.magnitude = magnitude\n",
        "        self.image_size = image_size\n",
        "\n",
        "    def load_image(self, path, label=None):\n",
        "        \"\"\"\n",
        "        file pathを受け取り、float32型のtensorを返す。\n",
        "        \"\"\"\n",
        "        image = tf.io.read_file(path)\n",
        "        image = tf.image.decode_jpeg(image, channels=3)\n",
        "        image = tf.cast(image, tf.float32)\n",
        "        return image, label\n",
        "\n",
        "    def mix_up(self, ds1, ds2, alpha=0.2):\n",
        "        \"\"\"\n",
        "        拡張法：2枚の画像とそのラベルをランダムな割合で合成する。\n",
        "        \"\"\"\n",
        "        lam = tf.random.uniform(shape=[], maxval=0.11, dtype=tf.float32)\n",
        "        image = tf.add(tf.multiply(ds1[0], (1 - lam)), tf.multiply(ds2[0], lam))\n",
        "        label = tf.add(tf.multiply(ds1[1], (1 - lam)), tf.multiply(ds2[1], lam))\n",
        "        return image, label\n",
        "\n",
        "    def random_rotate(self, image, label=None):\n",
        "        \"\"\"\n",
        "        拡張法：ランダムな角度(度数法)で画像を回転する。\n",
        "        \"\"\"\n",
        "        level = np.pi * self.magnitude / 180 # 度数法を孤度法へ変換\n",
        "\n",
        "        angle = tf.random.uniform(\n",
        "            shape=[],minval=-level, maxval=level, dtype=tf.float32)\n",
        "        image = tfa.image.rotate(\n",
        "            image, angle, \n",
        "            fill_mode=\"nearest\"\n",
        "            )\n",
        "        return image, label\n",
        "\n",
        "    def random_cutout(self, image, label=None):\n",
        "        \"\"\"\n",
        "        拡張法：画像のランダムな一部をに黒塗りにする。\n",
        "        黒塗りは正方形となり、一辺の長さが偶数でなくてはならない。\n",
        "        \"\"\"\n",
        "        mask = int(7 + 3 * self.magnitude) * 2\n",
        "        image = tf.reshape(image, [1, Config.original_size, Config.original_size, 3])\n",
        "        image = tfa.image.random_cutout(image, (mask, mask))\n",
        "        return image[0], label\n",
        "\n",
        "    def random_brightness(self, image, label=None):\n",
        "        \"\"\"\n",
        "        拡張法：輝度をランダムに変化させる。\n",
        "        \"\"\"\n",
        "        bright_delta = 0.05 * self.magnitude\n",
        "        image = tf.image.random_brightness(image, bright_delta)\n",
        "        return image, label\n",
        "\n",
        "    def random_contrast(self, image, label=None):\n",
        "        \"\"\"\n",
        "        拡張法：コントラストをランダムに変化させる。\n",
        "        \"\"\"\n",
        "        lower = 0.8 - 0.06 * self.magnitude\n",
        "        upper = 1.1 + 0.09 * self.magnitude\n",
        "        image = tf.image.random_contrast(image, lower=lower, upper=upper)\n",
        "        return image, label\n",
        "    \n",
        "    def random_saturation(self, image, label=None):\n",
        "        \"\"\"\n",
        "        拡張法：彩度をランダムに変化させる。\n",
        "        \"\"\"\n",
        "        lower = 0.8 - 0.079 * self.magnitude\n",
        "        upper = 1.1 + 0.09 * self.magnitude\n",
        "        image = tf.image.random_saturation(image, lower=lower, upper=upper)\n",
        "        return image, label\n",
        "    \n",
        "    def random_hue(self, image, label=None):\n",
        "        \"\"\"\n",
        "        拡張法：色相をランダムに変化させる。\n",
        "        \"\"\"\n",
        "        hue_delta = 0.01 + 0.005 * self.magnitude #0819 0.004->0.005\n",
        "        image = tf.image.random_hue(image, hue_delta)\n",
        "        return image, label\n",
        "       \n",
        "    def random_flip(self, image, label=None):\n",
        "        \"\"\"\n",
        "        拡張法：ランダムな割合で左右を反転する。\n",
        "        \"\"\"\n",
        "        image = tf.image.random_flip_left_right(image)\n",
        "        return image, label\n",
        "\n",
        "    def random_zoom(self, image, label=None):\n",
        "        \"\"\"\n",
        "        拡張法：ランダムな焦点にズームする。\n",
        "        \"\"\"\n",
        "        zoom_rate = 0.05 + 0.035 * self.magnitude\n",
        "        crop_size = tf.random.uniform(\n",
        "            shape=[], \n",
        "            minval=int(Config.original_size*(1. - zoom_rate)), \n",
        "            maxval=Config.original_size, \n",
        "            dtype=tf.int32)\n",
        "        image = tf.image.random_crop(image, size=[crop_size, crop_size, 3])\n",
        "        image = tf.image.resize(image, size=[Config.original_size, Config.original_size])\n",
        "        return image, label\n",
        "\n",
        "    def random_sharpness(self, image, label=None):\n",
        "        \"\"\"\n",
        "        拡張法：輪郭の強調感をランダムに変化させる。\n",
        "        \"\"\"\n",
        "        factor = 0.01 + 0.089 * self.magnitude # 0819 0.009->0.089\n",
        "        factor = tf.random.uniform([], minval=0, maxval=factor)\n",
        "        image = tfa.image.sharpness(image, factor)\n",
        "        return image, label\n",
        "\n",
        "    def random_shear_x(self, image, label=None):\n",
        "        \"\"\"\n",
        "        拡張法：ランダムに水平せん断写像を行う。\n",
        "        \"\"\"\n",
        "        level = 0.02 + 0.015 * self.magnitude # 0819 0.018->0.015\n",
        "        level = tf.random.uniform([], minval=-level, maxval=level)\n",
        "        image = tfa.image.shear_x(image, level, [128,128,128])\n",
        "        return image, label\n",
        "\n",
        "    def random_shear_y(self, image, label=None):\n",
        "        \"\"\"\n",
        "        拡張法：ランダムに鉛直せん断写像を行う。\n",
        "        \"\"\"\n",
        "        level = 0.02 + 0.015 * self.magnitude # 0819 0.018->0.015\n",
        "        level = tf.random.uniform([], minval=-level, maxval=level)\n",
        "        image = tfa.image.shear_y(image, level, [128,128,128])\n",
        "        return image, label\n",
        "\n",
        "    def random_solarize_add(self, image, label=None):\n",
        "        \"\"\"\n",
        "        拡張法：ランダムな露出効果を付加する。\n",
        "        \"\"\"\n",
        "        addition = np.round(1 + 0.9 * self.magnitude)\n",
        "        threshold = 1 + 3.1 * self.magnitude\n",
        "        addition = tf.random.uniform([], minval=-addition, maxval=addition+1, dtype=tf.int64)\n",
        "        threshold = tf.random.uniform([], minval=0, maxval=threshold)\n",
        "        # tf.print(\"addition:\", addition)\n",
        "        # tf.print(\"threshold:\", threshold)\n",
        "        added_image = tf.add(tf.cast(image, tf.int64), addition)\n",
        "        added_image = tf.cast(tf.clip_by_value(added_image, 0, 255), tf.float32)\n",
        "        image = tf.where(image < threshold, added_image, image)\n",
        "        return image, label\n",
        "\n",
        "    def random_posterize(self, image, label=None):\n",
        "        \"\"\"\n",
        "        拡張法：ランダムに色数を削減する。\n",
        "        \"\"\"\n",
        "        shift = np.round(0.6 * self.magnitude)\n",
        "        shift = tf.random.uniform([], minval=0, maxval=shift+1, dtype=tf.int32)\n",
        "        # tf.print(\"shift:\", shift)\n",
        "        image = tf.cast(image, tf.int32)\n",
        "        image =  tf.bitwise.left_shift(tf.bitwise.right_shift(image, shift), shift)\n",
        "        image = tf.cast(image, tf.float32)\n",
        "        return image, label\n",
        "\n",
        "    def identity(self, image, label=None):\n",
        "        \"\"\"\n",
        "        恒等関数\n",
        "        \"\"\"\n",
        "        return image, label\n",
        "\n",
        "    def resize_divide_image(self, image, label=None):\n",
        "        \"\"\"\n",
        "        モデルの入力形式に画像を調整する。\n",
        "        \"\"\"\n",
        "        image = tf.image.resize(image, size=[self.image_size, self.image_size])\n",
        "        image = tf.math.divide(image, 255)\n",
        "        return image, label\n",
        "        \n",
        "    def augment_fns(self, ops, image, label=None):\n",
        "        \"\"\"\n",
        "        上で定義した拡張法を数字で呼び出し、画像に施す。\n",
        "\n",
        "        Parameters\n",
        "        ------------\n",
        "            ops : int\n",
        "                呼び出す拡張法を指定する。\n",
        "        \"\"\"\n",
        "        branch_fns = {\n",
        "            0: lambda: self.random_zoom(image, label),\n",
        "            1: lambda: self.random_shear_x(image, label),\n",
        "            2: lambda: self.random_shear_y(image, label),\n",
        "            3: lambda: self.random_brightness(image, label),\n",
        "            4: lambda: self.random_contrast(image, label),\n",
        "            5: lambda: self.random_saturation(image, label),\n",
        "            6: lambda: self.random_hue(image, label),\n",
        "            7: lambda: self.random_sharpness(image, label),\n",
        "            8: lambda: self.random_flip(image, label),\n",
        "            9: lambda: self.random_solarize_add(image, label),\n",
        "            10: lambda: self.random_posterize(image, label),\n",
        "            11: lambda: self.random_cutout(image, label),\n",
        "            12: lambda: self.random_rotate(image, label)\n",
        "        }\n",
        "        image, label = tf.switch_case(\n",
        "            ops, \n",
        "            branch_fns=branch_fns, \n",
        "            default=lambda: self.identity(image, label))\n",
        "        return image, label\n",
        "\n",
        "    def random_augment(self, image, label):\n",
        "        \"\"\"\n",
        "        拡張法をself.num_ops回ランダムに呼び出し、画像に施す。\n",
        "        \"\"\"\n",
        "        available_ops = [\"zoom\",\"shear_x\",\"shear_y\",\"flip\",\n",
        "                        \"brightness\",\"contrast\",\"saturation\",\"hue\",\"sharpness\",\n",
        "                        \"solarize_add\",\"posterize\",\"cutout\",\"rotate\"]\n",
        "        ops = tf.random.uniform(\n",
        "            [self.num_ops], maxval=len(available_ops), dtype=tf.int32)\n",
        "        # tf.print(\"ops :\", ops)\n",
        "        for op in ops:\n",
        "            image, label = self.augment_fns(op, image, label)\n",
        "\n",
        "        return image, label\n",
        "\n",
        "    def tr_dataset(self, file_path, label, batch_size=Config.batch_size, mix=True):\n",
        "        \"\"\"\n",
        "        全ての拡張法を一度ずつ適用する。\n",
        "        \"\"\"\n",
        "        num_files = file_path.shape[0]\n",
        "        tr_ds = tf.data.Dataset.from_tensor_slices((file_path, label))\n",
        "        tr_ds = tr_ds.map(self.load_image, num_parallel_calls=AUTOTUNE)\n",
        "        # tr_ds = tr_ds.repeat()\n",
        "\n",
        "        if mix:\n",
        "            another_ds =tr_ds.shuffle(num_files)\n",
        "            zip_ds = tf.data.Dataset.zip((tr_ds, another_ds))\n",
        "            tr_ds = zip_ds.map(self.mix_up, num_parallel_calls=AUTOTUNE)\n",
        "\n",
        "        tr_ds = tr_ds.shuffle(num_files)\n",
        "        tr_ds = tr_ds.map(self.random_flip, num_parallel_calls=AUTOTUNE)\n",
        "        tr_ds = tr_ds.map(self.random_shear_x, num_parallel_calls=AUTOTUNE)\n",
        "        tr_ds = tr_ds.map(self.random_shear_y, num_parallel_calls=AUTOTUNE)\n",
        "        tr_ds = tr_ds.map(self.random_zoom, num_parallel_calls=AUTOTUNE) \n",
        "        tr_ds = tr_ds.map(self.random_brightness, num_parallel_calls=AUTOTUNE)\n",
        "        tr_ds = tr_ds.map(self.random_contrast, num_parallel_calls=AUTOTUNE)\n",
        "        tr_ds = tr_ds.map(self.random_saturation, num_parallel_calls=AUTOTUNE)\n",
        "        tr_ds = tr_ds.map(self.random_hue, num_parallel_calls=AUTOTUNE)\n",
        "        tr_ds = tr_ds.map(self.random_sharpness, num_parallel_calls=AUTOTUNE)   \n",
        "        tr_ds = tr_ds.map(self.random_solarize_add, num_parallel_calls=AUTOTUNE)\n",
        "        tr_ds = tr_ds.map(self.random_posterize, num_parallel_calls=AUTOTUNE) \n",
        "        tr_ds = tr_ds.map(self.random_cutout, num_parallel_calls=AUTOTUNE)\n",
        "        tr_ds = tr_ds.map(self.random_rotate, num_parallel_calls=AUTOTUNE)\n",
        "        tr_ds = tr_ds.batch(batch_size)\n",
        "        tr_ds = tr_ds.map(self.resize_divide_image, num_parallel_calls=AUTOTUNE)\n",
        "        tr_ds = tr_ds.prefetch(buffer_size=AUTOTUNE)\n",
        "        return tr_ds\n",
        "\n",
        "    def val_dataset(self, file_path, label=None, batch_size=Config.batch_size):\n",
        "        \"\"\"\n",
        "        validation用dataset\n",
        "        \"\"\"\n",
        "        val_ds = tf.data.Dataset.from_tensor_slices((file_path, label))\n",
        "        val_ds = val_ds.map(self.load_image, num_parallel_calls=AUTOTUNE)\n",
        "        val_ds = val_ds.repeat()\n",
        "        val_ds = val_ds.batch(batch_size)\n",
        "        val_ds = val_ds.map(self.resize_divide_image, num_parallel_calls=AUTOTUNE)\n",
        "        val_ds = val_ds.prefetch(buffer_size=AUTOTUNE)\n",
        "        return val_ds\n",
        "\n",
        "    def test_dataset(self, file_path, label=None, batch_size=Config.batch_size):\n",
        "        \"\"\"\n",
        "        test用dataset\n",
        "        \"\"\"\n",
        "        te_ds = tf.data.Dataset.from_tensor_slices((file_path, label))\n",
        "        te_ds = te_ds.map(self.load_image, num_parallel_calls=AUTOTUNE)\n",
        "        te_ds = te_ds.batch(batch_size)\n",
        "        te_ds = te_ds.map(self.resize_divide_image, num_parallel_calls=AUTOTUNE)\n",
        "        te_ds = te_ds.prefetch(buffer_size=AUTOTUNE)\n",
        "        return te_ds\n",
        "\n",
        "    def rand_aug_dataset(self, file_path, label, batch_size=Config.batch_size, mix=True):\n",
        "        \"\"\"\n",
        "        random augmentを適用して、dataset化\n",
        "        \"\"\"\n",
        "        num_files = file_path.shape[0]\n",
        "        tr_ds = tf.data.Dataset.from_tensor_slices((file_path, label))\n",
        "        tr_ds = tr_ds.map(self.load_image, num_parallel_calls=AUTOTUNE)\n",
        "        tr_ds = tr_ds.repeat()\n",
        "\n",
        "        if mix:\n",
        "            another_ds =tr_ds.shuffle(num_files)\n",
        "            zip_ds = tf.data.Dataset.zip((tr_ds, another_ds))\n",
        "            tr_ds = zip_ds.map(self.mix_up, num_parallel_calls=AUTOTUNE)\n",
        "\n",
        "        tr_ds.shuffle(num_files)\n",
        "        tr_ds = tr_ds.map(self.random_augment, num_parallel_calls=AUTOTUNE)\n",
        "        tr_ds = tr_ds.batch(batch_size)\n",
        "        tr_ds = tr_ds.map(self.resize_divide_image, num_parallel_calls=AUTOTUNE)\n",
        "        tr_ds = tr_ds.prefetch(buffer_size=AUTOTUNE)\n",
        "        return tr_ds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PkGp11rB_BGE"
      },
      "source": [
        "# 5.訓練準備\n",
        "訓練を補助する為の関数を定義します。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8SWhCHhKUnV1"
      },
      "source": [
        "## 5.1 損失関数、最適化アルゴリズム\n",
        "損失関数として、focal lossを使用します。<br>\n",
        "また、epoch数によって学習率を出力する関数を定義します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rFKL1L_KI-LU"
      },
      "source": [
        "def categorical_focal_loss(alpha, gamma=2.):\n",
        "    \"\"\"\n",
        "    focal loss関数\n",
        "    \"\"\"\n",
        "    alpha = np.array(alpha, dtype=np.float32)\n",
        "\n",
        "    def _categorical_focal_loss(y_true, y_pred):\n",
        "        epsilon = K.epsilon()\n",
        "        y_pred = K.clip(y_pred, epsilon, 1. - epsilon)\n",
        "        cross_entropy = -y_true * K.log(y_pred)\n",
        "        loss = alpha * K.pow(1 - y_pred, gamma) * cross_entropy\n",
        "\n",
        "        return K.mean(K.sum(loss, axis=-1))\n",
        "\n",
        "    return _categorical_focal_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4V32psHLxenz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "2c351df5-e337-4691-88de-6c52ab5f5596"
      },
      "source": [
        "def lr_schedule(epoch):\n",
        "    \"\"\"\n",
        "    学習率cosineアニーリング\n",
        "    \"\"\"\n",
        "\n",
        "    if epoch <= Config.begining:\n",
        "        return Config.lr_base + epoch * (Config.lr_max - Config.lr_base) / Config.begining        \n",
        "    elif (epoch > Config.begining) and (epoch <= Config.ending):\n",
        "        value = np.cos(np.pi * (epoch - Config.begining) / (Config.ending - Config.begining)) + 1\n",
        "        return value * (Config.lr_max - Config.lr_base) / 2 + Config.lr_base\n",
        "    else:\n",
        "        return (epoch - Config.epochs) * (Config.lr_min - Config.lr_base) / (Config.epochs - Config.ending)\n",
        "\n",
        "def lr_graph():\n",
        "    \"\"\"\n",
        "    学習率のグラフを表示\n",
        "    \"\"\"\n",
        "    from matplotlib import pyplot as plt\n",
        "\n",
        "    epoch_point = [i for i in range(100)]\n",
        "    lr_point = [lr_schedule(i) for i in range(100)]\n",
        "    plt.plot(epoch_point, lr_point)\n",
        "    plt.xlabel(\"epoch\")\n",
        "    plt.ylabel(\"learning rate\")\n",
        "\n",
        "lr_graph()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZQAAAEGCAYAAABCa2PoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXxU5fX48c+ZyQIJECCEPUgCyCoCRsStWpeCSxu1qNiv1qrVWuVr/Vmr0tpW6ddWq9XWVltxad0RcYvWpSp1axUIirJjEraAkoFAIPt2fn/MjcaYZUjm5s5y3q/XvJi589xnzmV0Dvc+5z6PqCrGGGNMV/m8DsAYY0xssIRijDEmLCyhGGOMCQtLKMYYY8LCEooxxpiwSPA6AC8NGDBAR44c6XUYxhgTVVasWLFLVTNabo/rhDJy5Ejy8/O9DsMYY6KKiGxpbbtd8jLGGBMWllCMMcaEhSUUY4wxYWEJxRhjTFhYQjHGGBMWriYUEZklIhtEpEBEbmjl/WQRecp5f6mIjGz23jxn+wYRmdlRnyLyroisdB47ROR5N4/NGGPMV7lWNiwifuAe4GSgGFguInmqurZZs0uAPao6WkTmALcB54rIBGAOMBEYCrwhIgc7+7Tap6oe2+yznwFecOvYjDHGfJ2b96FMBwpUtQhARBYCuUDzhJIL3OQ8Xwz8RUTE2b5QVWuATSJS4PRHR32KSB/gBOAil47LUy99soMtuyvpmegnJcnPwD7JjOifwvB+KfRI9HsdnjEmjrmZUIYB25q9LgaOaKuNqtaLSBmQ7mz/oMW+w5znHfV5BvCmqu5rLSgRuQy4DGDEiBGhHktEqKlv4CcLV9LQ2PoaNgelpzA1sy9TR/RjRnY6Bw/qRTA/G2OM+2LxTvnzgAfaelNVFwALAHJycqJqdbEtuytpaFRunz2ZkycMoqK2gZJ91WwtrWTr7krW7NjHfwt38/zKHQBk9u/JSeMHccqkIRw+sp8lF2OMq9xMKNuBzGavhzvbWmtTLCIJQBqwu4N92+xTRAYQvDR2ZhjijziFJeUAjB/Sh74pSfRNgWF9ezJ1RL8v2qgqO8qqeWdjgNfX7uTxpVv5+382kz0glXMPz+S7hw1nQK9krw7BGBPD3KzyWg6MEZEsEUkiOMie16JNHnCh83w2sESDaxLnAXOcKrAsYAywLIQ+ZwMvqWq1a0flocJAMKFkDUhts42IMKxvT86bPoKHfnA4H/3yZG6fPZn+qUn87pX1HHXrEn75/GqK91R2V9jGmDjh2hmKMyYyF3gN8AMPqeoaEZkP5KtqHvAg8Kgz6F5KMEHgtFtEcLC9HrhSVRsAWuuz2cfOAW5165i8VhioYGhaD1KTQ//aUpMTODsnk7NzMvl0534efG8TC5dv5cllWzlz6jCu+dbBDEnr6WLUxph4IcETgviUk5Oj0TTbcO5f3qNPz0QevaRlHcKB+aysigXvFPH40q34BC47NpsfHTfqgBKVMSZ+icgKVc1pud3ulI8SqkphoIJRGb263NeQtJ78+tsTefOa4zh5wmDuXlLAN+94i1dXfxaGSI0x8coSSpQo2V9DeU092Rltj58cqMz+Kfz5vKk8e8VRDOiVzOWPfcjlj66gZF9MDkEZY1xmCSVKNFV4heMMpaVpI/rxwtyjuW7WWJZsKOGkO9/mn5/Y2Yox5sBYQokSTRVebiQUgES/jyuOH82rPzmWrIxeXPnEh9zwzCdU1ta78nnGmNhjCSVKFAYqSE3yM6iPu/eQZGf0YvHlR/Lj40fxVP42vv3n9/h0535XP9MYExssoUSJwkA5owZ2z1QqiX4f188ax2OXHEFZVR1n3PMfXlvzueufa4yJbpZQokRRmCq8DsTRowfw4v8ew+iBvfjRoyu48/WNNLYxj5gxxlhCiQKVtfVs31tFdjt3yLtlSFpPnvrRkcw+bDh3v/kpVy38iOq6hm6PwxgT+exOtihQFKgAYNTA7j1DadIj0c/tsyczemAvbn1lPSX7a1hwwWH0TUnyJB5jTGSyM5Qo4HaFVyhEhMuPG8Wf5kxh5da9zP7b+2zfW+VZPMaYyGMJJQoUBSrwSXC9E6/lThnGI5dMZ+e+as752/ts2lXhdUjGmAhhCSUKFAbKyewfOSsyzshO58lLZ1BV18A5973PRisrNsZgCSUqhGsOr3CaNCyNpy6bgQDn3vc+q7eXeR2SMcZjllAiXGOjsmlXOaPCOIdXuIwZ1JunLz+SlKQEzn9wKes+a3XVZWNMnLCEEuG2762iuq6R7Ag7Q2lyUHoqT1x6BD0S/Jz/wFK7q96YOGYJJcJFQoVXR5qSis8nnHf/UoqcmI0x8cUSSoT74h6UCLzk1Vx2Ri+evPQIVJULHlzG52U2Bb4x8cYSSoQrDJTTNyWR/qmRfxPh6IG9efji6ZRV1fH9h5ayt7LW65CMMd3IEkqEKwyUMyqjeyaFDIdJw9JY8P3D2Lyrkov/sZyqWpumxZh4YQklwhUGKjyZw6srjho1gLvPm8LKbXuZ+8SHNNiEksbEBVcTiojMEpENIlIgIje08n6yiDzlvL9UREY2e2+es32DiMzsqE8JukVENorIOhG5ys1j6w77qusI7K/xbA6vrpg1aQg3f2cib64v4TcvrfU6HGNMN3BtckgR8QP3ACcDxcByEclT1ea/LpcAe1R1tIjMAW4DzhWRCcAcYCIwFHhDRA529mmrzx8AmcA4VW0UkYFuHVt3+XJAPvoSCsAFR45ky+5KHnhvEyP6p3DxMVleh2SMcZGbZyjTgQJVLVLVWmAhkNuiTS7wsPN8MXCiBAcLcoGFqlqjqpuAAqe/9vr8MTBfVRsBVLXExWPrFl+uIx9dl7ya+/mp45k5cRC/+edaXl+70+twjDEucjOhDAO2NXtd7GxrtY2q1gNlQHo7+7bX5yiCZzf5IvKKiIxpLSgRucxpkx8IBDp1YN2lMFBOol/I7O/9pJCd5fMJfzx3KpOHpXH1wo9Y/7ndTW9MrIqlQflkoFpVc4D7gYdaa6SqC1Q1R1VzMjIyujXAA1UYKGdE/xQS/dH9NfVM8nPfBTmkJidw6SP5lFZYObExscjNX6rtBMc0mgx3trXaRkQSgDRgdzv7ttdnMfCs8/w5YHKXj8BjkTgpZGcNTuvBfRccxs59NVzx+ArqGhq9DskYE2ZuJpTlwBgRyRKRJIKD7Hkt2uQBFzrPZwNLVFWd7XOcKrAsYAywrIM+nwe+6Tw/Dtjo0nF1i/qGRrbsrojKCq+2TB3Rj1vPOoQPikqt8suYGORalZeq1ovIXOA1wA88pKprRGQ+kK+qecCDwKMiUgCUEkwQOO0WAWuBeuBKVW0AaK1P5yNvBR4Xkf8HlAM/dOvYusO2PVXUNWjMnKE0OWvacNZ9to/7393ElMy+nDVtuNchGWPCxNU15VX1ZeDlFtt+1ex5NXB2G/veAtwSSp/O9r3AaV0MOWLEQoVXW66fNY5V28v4+XOrGDe4DxOG9vE6JGNMGET3aG8Ma5plOFKnre+KBL+PP583jbSeiVz+2ArKKuu8DskYEwaWUCJUYaCcAb2SSeuZ6HUorsjoncy9/3MYn5VVcc2ilTTa9CzGRD1LKBGqKFARk5e7mjvsoH784tTxvLm+hAfeK/I6HGNMF1lCiVCFgfKYqvBqy4VHjWTWxMH8/tUNrNiyx+twjDFdYAklApVW1LKnsi7qZhnuDBHhttmTGdK3B1c9+ZGtoWJMFLOEEoGaBuRHx8EZCkBaz0Tu+d40SvZXc+3THxO8FckYE20soUSgL0uG4yOhAEwe3pd5p4znjXUlPPL+Fq/DMcZ0giWUCFQYKCc5wcfQvj29DqVbXXT0SL45NoNbXl5nk0gaE4UsoUSgokAFWQNS8fuiY9nfcBERbj/7UPr0SOSqJz+ius6WDzYmmlhCiUDxUuHVmgG9krnznEPZuLOc//unzfdlTDSxhBJhauob2FpaGVfjJy194+AMLj02i8c+2MqS9bYolzHRwhJKhNmyu5JGjc05vA7EtTPHMm5wb65bvIrd5TVeh2OMCYEllAgTjxVerUlO8PPHOVPYV1XHvGdXWSmxMVHAEkqEKdpVAUBWHNzU2JFxg/vws5lj+dfanTy9otjrcIwxHbCEEmEKS8oZmtaD1GRXVxaIGpcck8WM7P7cnLeGbaWVXodjjGmHJZQIE88VXq3x+YQ7zj4UEeG6xZ/YrMTGRDBLKBFEVSkMVMTFHF4HYni/FG48bTzvF+3m0Q/sLnpjIpUllAhSsr+G8pp6O0NpxbmHZ3L82AxufWU9m51xJmNMZLGEEkGaJoWM9wqv1ogIt541mUS/cO3TH9Ngl76MiTiuJhQRmSUiG0SkQERuaOX9ZBF5ynl/qYiMbPbePGf7BhGZ2VGfIvIPEdkkIiudxxQ3j80NhYHgv7wtobRucFoPbvrORPK37OEf/93sdTjGmBZcSygi4gfuAU4BJgDniciEFs0uAfao6mjgLuA2Z98JwBxgIjALuFdE/CH0+TNVneI8Vrp1bG4pLCknNcnPoD7JXocSsc6cOowTxw3k9tfWs2W3XfoyJpK4eYYyHShQ1SJVrQUWArkt2uQCDzvPFwMniog42xeqao2qbgIKnP5C6TNqNVV4Bf8KTGtEhFvOPIREn8+qvoyJMG4mlGHAtmavi51trbZR1XqgDEhvZ9+O+rxFRD4RkbtEJOr+mV9kFV4hGZzWgxtPH8/STaU8vtSqvoyJFLE0KD8PGAccDvQHrm+tkYhcJiL5IpIfCAS6M752VdbWs31vlY2fhOicnEyOHTOA372ynuI9dsOjMZHAzYSyHchs9nq4s63VNiKSAKQBu9vZt80+VfUzDaoB/k7w8tjXqOoCVc1R1ZyMjIxOHlr4bXJKYbMtoYRERPjdWYcAcOPzq22uL2MigJsJZTkwRkSyRCSJ4CB7Xos2ecCFzvPZwBIN/jLkAXOcKrAsYAywrL0+RWSI86cAZwCrXTy2sGuq8IqXdeTDYXi/FH42cyxvbQjwwsodXodjTNxzbcIoVa0XkbnAa4AfeEhV14jIfCBfVfOAB4FHRaQAKCWYIHDaLQLWAvXAlaraANBan85HPi4iGYAAK4HL3To2NxSWlOMTOCg9xetQosr3jxzJCyt3cPOLazh2zADSe0Xd0JkxMUPi+VJBTk6O5ufnex0GAHOf+JBPist457pveh1K1Nm4cz+n3f0upx0yhD/Omep1OMbEPBFZoao5LbfH0qB8VCsMVMT9olqddfCg3lxx/GieX7mDtzaUeB2OMXHLEkoEaGxUNu0qtwqvLrjim6MYlZHKjc+vprK23utwjIlLllAiwI6yKqrrGm1SyC5ITvDzu7MmU7ynij++8anX4RgTlyyhRACbwys8pmf157zpmTz43ibW7CjzOhxj4o4llAjQtI58to2hdNkNs8bTLyWJec+ushmJjelmllAiQGGgnLSeiaSnJnkdStRLS0nk19+ewCfFZTzy/mavwzEmrnSYUETkYBF5U0RWO68ni8iN7ocWP4qcCi+bFDI8Tp88hOMOzuAP/9rI52XVXodjTNwI5QzlfoLzZNUBqOonODcgmvAoDFiFVziJCL/JnURdQyPzX1rT8Q7GmLAIJaGkqOqyFtusLjNM9lXXUbK/xiq8wmxEegpXnTiGl1d9zr/X270pxnSHUBLKLhEZBSiAiMwGPnM1qjhSZBVerrn02GxGD+zFL19YTVVtg9fhGBPzQkkoVwL3AeNEZDtwNVE2T1Ykswov9yQl+LjljEkU76ni7iV2b4oxbgsloaiqngRkAONU9ZgQ9zMhKAyUk+ATRvS3SSHdcER2OrMPG84D7xZRULLf63CMiWmhJIZnAFS1QlWb/o9c7F5I8aUoUMFB6Skk+i1Hu2XeKeNISUqwdVOMcVmbv2IiMk5EvgukichZzR4/AHp0W4Qxziq83JfeK5nrZo3lg6JSnl/Zco03Y0y4tPfP4rHA6UBf4NvNHtOAS90PLfbVNzSyeXeFVXh1gzmHj+DQzL7c8s91lFXVeR2OMTGpzYSiqi+o6kXA6ap6UbPHVar6326MMWZt21NFXYOSPcAG5N3m9wm3nDGJ0opa7nhtg9fhGBOTQlmx8SMRuRKYSLNLXap6sWtRxYkvK7zsDKU7TBqWxgUzDuLRD7Zw7uGZTBqW5nVIxsSUUEaCHwUGAzOBt4HhgJXLhEHRrmBCGW0Jpdtc862x9E9N4sbnV9Nok0caE1ahJJTRqvpLoEJVHwZOA45wN6z4UFhSwYBeyaSlJHodStxI65nIvFPGs3LbXhblb/M6HGNiSigJpWkEc6+ITALSgIHuhRQ/ghVeNn7S3c6aNozpI/tz26vr2VNR63U4xsSMUBLKAhHpB9wI5AFrgdtC6VxEZonIBhEpEJEbWnk/WUSect5fKiIjm703z9m+QURmHkCfd4tIeSjxea0wUG7jJx4QEeafMZF91fX83gbojQmbdhOKiPiAfaq6R1XfUdVsVR2oqvd11LGI+IF7gFOACcB5IjKhRbNLgD2qOhq4CydROe3mECwEmAXcKyL+jvoUkRygXygH7rXSilr2VNbZGYpHxg3uww+OGsnC5Vv5eNter8MxJia0m1BUtRG4rpN9TwcKVLVIVWuBhUBuiza5wMPO88XAiRJcFCQXWKiqNaq6CShw+muzTyfZ3N6FeLtVUSB4EmX3oHjn6pPGMKBXMr96wQbojQmHUC55vSEi14pIpoj0b3qEsN8woPmoZ7GzrdU2qloPlAHp7ezbXp9zgTxVbXcmZBG5TETyRSQ/EAiEcBjuKAxYhZfXevdI5Benjufj4jKesgF6Y7oslIRyLsEZh98BVjiPfDeDOlAiMhQ4G/hzR21VdYGq5qhqTkZGhvvBtaEwUEFygo+hfXt6FoOB3ClDmZ7Vn9/bAL0xXdZhQlHVrFYe2SH0vR3IbPZ6uLOt1TYikkCwgmx3O/u2tX0qMBooEJHNQIqIFIQQo2cKS8rJGpCK32fL/nqpaXXHfdX13P4vG6A3pivcnOJ2OTBGRLJEJIngIHteizZ5wIXO89nAEg1OB5sHzHGqwLKAMcCytvpU1X+q6mBVHamqI4FKZ6A/YtmkkJFj7ODeXHjkSJ5ctpVVxWVeh2NM1HItoThjInOB14B1wCJVXSMi80XkO06zB4F052ziGuAGZ981wCKCJcqvAleqakNbfbp1DG6pqW9ga2mlVXhFkKtPHkN6ajK/tAF6YzotlLm8Ok1VXwZebrHtV82eVxMc+2ht31uAW0Lps5U2Ef1P/627K2lUq/CKJH16JDLvlHH89OmPWbyimHMOz+x4J2PMV3R4hiIi01p5jHLGPEwnNFV42SWvyHLWtGHkHNSPW19dT1mlTXFvzIEK5ZLXvcAHwALgfuB94Glgg4h8y8XYYlZhoAKALJu2PqKICDfnTmRvZS1/eN0G6I05UKEklB3AVKfU9jCCFVVFwMnA790MLlYVlpQzJK0Hqcl2khdpJg5N4/wZB/HYB1tYu2Of1+EYE1VCSSgHNx/4VtW1wDhVLXIvrNhmFV6R7acnj6VvShK/zrM16I05EKEklDUi8lcROc553AusFZFkvpyJ2IRIVSkKVFiFVwRLS0nk+lljWb55j61Bb8wBCCWh/IDgXFpXO48iZ1sd8E23AotVgf017K+ptwqvCHf2YZkcOjyN3768nv3V9u8mY0IRyp3yVar6B1U903ncoaqVqtqoqlExTXwkKbAKr6jg8wnzcyexq7yGP73xqdfhGBMVQikbPlpEXheRjSJS1PTojuBiUVOFV7Zd8op4h2b25dycTP7x3818utNWvTamI6Fc8noQuBM4Bji82cN0QmFJOalJfgb36eF1KCYEP5s5lpQkPze9uMYG6I3pQCgJpUxVX1HVElXd3fRwPbIY1bRKY3DZFxPp0nslc+3MsfynYDevrP7c63CMiWihJJR/i8jtInJk87vlXY8sRlmFV/T53vQRjB/Sh/97aS2VtfVeh2NMxAoloRwB5AC/Bf7gPO5wM6hYVVXbwPa9VTYgH2US/D7m505kR1k1f1kS0asiGOOpDm/VVlUrDQ6Tol227G+0Onxkf86aOowH3t3E2TmZNm2OMa1oM6GIyPmq+piIXNPa+6p6p3thxSar8IpuN5wyjn+t3cnNL67h7z843MbBjGmhvUteTb96vdt4mANUWFKOCIxMt4QSjQb26cHVJ43hrQ0B3lhX4nU4xkScNs9QVPU+58+buy+c2Fa0q4LMfin0SPR7HYrppAuPGslTy7dx84trOHbMAPsujWkmlBsbM0Tk5yKyQEQeanp0R3CxprCk3Cq8olyi38fNuRMp3lPF394u9DocYyJKKFVeLwBpwBvAP5s9zAFobFSKdtksw7HgqFEDOH3yEO59q5Ctuyu9DseYiBFKQklR1etVdZGqPtP0cD2yGLOjrIrqukar8IoRvzhtPAk+Yf5LazpubEycCCWhvCQip7oeSYz7osLLyk1jwpC0nlx14hjeWFfCkvU7vQ7HmIgQSkL5CcGkUiUi+0Rkv4iEtJSdiMwSkQ0iUiAiN7TyfrKIPOW8v1RERjZ7b56zfYOIzOyoTxF5UEQ+FpFPRGSxiETUqUBhid2DEmsuPjqLURmp3JS3luq6Bq/DMcZz7SYUEfEBs1TVp6o9VbWPqvZW1T4ddSwifuAe4BRgAnCeiExo0ewSYI+qjgbuAm5z9p0AzAEmArOAe0XE30Gf/09VD1XVycBWYG4ofwHdpWhXOWk9E0lPTfI6FBMmSQk+5udOYmtpJQvesQm4jWk3oahqI/CXTvY9HShQ1SJVrQUWArkt2uQCDzvPFwMnSvBusVxgoarWqOomggt8TW+vT1XdB+Ds3xOIqKlhC0uCc3jZzXCx5ejRAzjtkCHc8+8CtpXaAL2Jb6Fc8npTRL4rB/5LOAzY1ux1sbOt1TaqWg+UAent7NtunyLyd+BzYBzw59aCEpHLRCRfRPIDgcABHlLn2TrysevG08fj9wk3v2gD9Ca+hZJQfgQ8DdQc6BhKd1PVi4ChwDrg3DbaLFDVHFXNycjI6Ja49lXXUbK/hmxLKDFpSFpPfuIM0L+x1gboTfwKZQng3s4YStKBjKEA24HMZq+HO9tabSMiCQTvd9ndzr4d9qmqDQQvhX03hBi7RZFT4WU3Ncaui4/JYszAXtz04hqqam2A3sSnUM5QEJF+IjJdRL7R9Ahht+XAGBHJEpEkgoPseS3a5AEXOs9nA0s0uCxeHjDHqQLLAsYAy9rqU4JGO7EK8B1gfSjH1h2KnHXk7QwldiX6gwP0xXuquPctm+LexKcOp68XkR8SLB0eDqwEZgDvAye0t5+q1ovIXOA1wA88pKprRGQ+kK+qeQSXF35URAqAUoIJAqfdImAtUA9c6Zx50EafPuBhEekDCPAx8OMD+6twT2GgnASfcFB6itehGBcdOSqdM6YM5b63izhr2nCb4t7EHelonWwRWUVwDfkPVHWKiIwDfquqZ3VHgG7KycnR/Px81z/n8kdX8GnJft786fGuf5bxVsn+ak68422mjOjLIxdPt6o+E5NEZIWq5rTcHsolr2pVrXY6SVbV9cDYcAcYy5rWkTexb2DvHlw7cyzvfrqLf676zOtwjOlWoSSUYhHpCzwPvC4iLwBb3A0rdtQ3NLJ5d4WVDMeR82ccxMShfZj/4lr2V9d5HY4x3SaUKq8zVXWvqt4E/JLguMcZbgcWK7btqaKuQa3CK474fcItZx5CoLyGP77xqdfhGNNtQq3yOkZELlLVtwkOyLe8QdG0webwik9TMvvyvekj+Md/N7NmR5nX4RjTLUJZYOvXwPXAPGdTIvCYm0HFkqJdTkIZYAkl3lw3cxz9UhL5xXOraWiMqJmAjHFFKGcoZxK8r6MCQFV3YGvKh6ywpIIBvZJJS0n0OhTTzdJSErnxtAms3LaXJ5Zt9TocY1wXSkKpdW42VAARscGAAxCs8LK/sniVO2UoR49O5/evrqdkf7XX4RjjqlASyiIRuQ/oKyKXElwK+H53w4odNilkfBMRfpM7iZq6Rn7z0jqvwzHGVaFUed1BcGr5Zwjef/IrVW11Jl/zVaUVteyprLMKrziXndGLK745ihc/3sHbG7tvhmtjultIVV6q+rqq/kxVr1XV190OKlYUBqzCywT9+PhRZGekcuPzq2zySBOz2kwoTdPUt/KI2OnrI01TyfBou+QV95IT/Pz2zEPYVlrFH9/c6HU4xriizYTSNE19K49Qp6+Pe0W7KkhK8DG0b0+vQzERYEZ2OufkDOeBdzexdof9m8zEnpAueZnOKSwpJ3tAKn6fTRBogn5+6nj69kxk3nOr7N4UE3MsobjIKrxMS31TkvjVtyfw8ba9PPL+Zq/DMSasLKG4pKa+ga2llVbhZb7mO4cO5fixGdz+2gaK91R6HY4xYWMJxSVbdlfSqFbhZb5ORPi/MyYB8PPnVtPRmkTGRAtLKC5pqvDKtjm8TCuG90vhupljeWdjgOdXbvc6HGPCwhKKS5ruQcmyS16mDRccOZJpI/oy/8W17Cqv8TocY7rMEopLigIVDEnrQa/kBK9DMRHK7xNu++5kymvquSlvjdfhGNNlriYUEZklIhtEpEBEbmjl/WQRecp5f6mIjGz23jxn+wYRmdlRnyLyuLN9tYg8JCKeTu9rFV4mFGMG9eaqE8bw0ief8erqz70Ox5gucS2hiIgfuAc4BZgAnCciE1o0uwTYo6qjgbuA25x9JwBzgInALOBeEfF30OfjwDjgEKAn8EO3jq0jqkphoMIqvExILj9+FBOG9OHG51ezt7LW63CM6TQ3z1CmAwWqWqSqtcBCILdFm1zgYef5YuBEERFn+0JVrVHVTUCB01+bfarqy+oAlgHDXTy2dpXsr6G8pp5sO0MxIUj0+7j97Mnsraxl/ktrvQ7HmE5zM6EMA7Y1e13M15cO/qKNqtYDZUB6O/t22KdzqesC4NXWghKRy0QkX0TyAwF3Zn79YtlfSygmRBOHpvHj40fx7IfbWbJ+p9fhGNMpsTgofy/wjqq+29qbqrpAVXNUNScjI8OVAAp3VQAwaqBd8jKhm3vCaMYO6s0Nz6yyS18mKrmZUNeJr68AABIESURBVLYDmc1eD3e2tdpGRBKANGB3O/u226eI/BrIAK4JyxF0UmFJOSlJfgb36eFlGCbKJCf4+cM5h1JaUWtVXyYquZlQlgNjRCRLRJIIDrLntWiTB1zoPJ8NLHHGQPKAOU4VWBYwhuC4SJt9isgPgZnAeara6OJxdaipwis4HGRM6CYNS2PuCaN5fuUOq/oyUce1hOKMicwFXgPWAYtUdY2IzBeR7zjNHgTSRaSA4FnFDc6+a4BFwFqCYyFXqmpDW306ff0NGAS8LyIrReRXbh1bR4qswst0wZXfHM2kYX34xXOr2G03PJooIvE8j1BOTo7m5+eHtc/K2nom/Oo1rjn5YK46cUxY+zbxY8Pn+/n2n9/jhHED+ev50+xs10QUEVmhqjktt8fioLynigLOgLxVeJkuGDu4Nz/91sG8uuZznvnQ5voy0cESSpgVWYWXCZMfHpvNEVn9uSlvDdtKbZp7E/ksoYRZYUk5IjAy3RKK6Rq/T/jDOYciwE8XfWwrPJqIZwklzAoD5WT2S6FHot/rUEwMGN4vhZtzJ7Jscyn3vVPodTjGtMsSSpgVBirItgovE0ZnTh3GaZOHcOe/NrJy216vwzGmTZZQwqixUdm0y2YZNuElIvz2jEMY1KcHP1n4EeU19V6HZEyrLKGE0Y6yKqrrGi2hmLBLS0nkrnOnsK20kl+9sNrrcIxplSWUMCr8omTYLnmZ8Jue1Z+5J4zh2Q+384ItG2wikCWUMPpiluGBdoZi3HHVCaPJOagfP392FZucEnVjIoUllDAqDJTTp0cC6alJXodiYlSC38fd500lMcHHFY9/SHVdg9chGfMFSyhhVBgoZ9RAmxTSuGto357cec6hrPtsH7+xBblMBLGEEkbBZX/tcpdx3wnjBvGj47J5fOlWXvx4h9fhGANYQgmbfdV1BPbXWEIx3ebab43lsIP6cf0zn1BQst/rcIyxhBIuRVbhZbpZot/HPd+bRkqSnx89usLuTzGes4QSJlbhZbwwOK0Hfz5vGpt3V3Ld4o+J5+UojPcsoYRJYaCcBJ8won+K16GYOHPkqHSunzWWl1d9zv3vFnkdjoljllDCpDBQzoj0FBL99ldqut+lx2Zz6iGDufWV9by9MeB1OCZO2a9fmBRZhZfxkIhw++xDOXhQb/73iQ8pCpR7HZKJQ5ZQwqC+oZHNuy2hGG+lJidw//dzSPD7+OEj+eyrrvM6JBNnLKGEwbY9VdQ1qFV4Gc9l9k/h3v+ZxtbdlfzvEx9R39DodUgmjriaUERklohsEJECEbmhlfeTReQp5/2lIjKy2XvznO0bRGRmR32KyFxnm4rIADePq6WmCq9sO0MxEWBGdjrzcyfx9sYAN724xiq/TLdxLaGIiB+4BzgFmACcJyITWjS7BNijqqOBu4DbnH0nAHOAicAs4F4R8XfQ53+Ak4Atbh1TWwqd69V2hmIixfeOGMGPvpHNYx9s5YF3N3kdjokTbp6hTAcKVLVIVWuBhUBuiza5wMPO88XAiRKcCCsXWKiqNaq6CShw+muzT1X9SFU3u3g8bSoKVDCgVxJ9U2xSSBM5rp81jlMPGcxvX1nHK6s+8zocEwfcTCjDgG3NXhc721pto6r1QBmQ3s6+ofTZLhG5TETyRSQ/EAhPeWVhoNwud5mI4/MJd54zhSmZfbn6qZUs21TqdUgmxsXdoLyqLlDVHFXNycjICEufhQFb9tdEph6Jfh688HCG9evJJQ8vZ91n+7wOycQwNxPKdiCz2evhzrZW24hIApAG7G5n31D67FalFbXsqayz8RMTsfqnJvHIxdNJTUrg+w8tY1tppdchmRjlZkJZDowRkSwRSSI4yJ7Xok0ecKHzfDawRIMlKXnAHKcKLAsYAywLsc9u9eWAvJ2hmMg1vF8Kj1wyndr6Rs5/cCk791V7HZKJQa4lFGdMZC7wGrAOWKSqa0Rkvoh8x2n2IJAuIgXANcANzr5rgEXAWuBV4EpVbWirTwARuUpEigmetXwiIg+4dWzNFVlCMVHi4EG9+ftFh7Nrfw3fu/8DAvtrvA7JxBiJ5xr1nJwczc/P71Ifv315Hf/472bWzZ+F32crNZrIt7RoNz/4+3JG9E/hyctm0N+WrDYHSERWqGpOy+1xNygfboUl5WSlp1oyMVHjiOx0Hrgwh827Kzj/gaWUVtR6HZKJEZZQuqgwUM5oWwPFRJmjRw9gwfdzKAyUM2fB+5TYmIoJA0soXVBT38DW0kqyrcLLRKHjDs7g7xcdTvGeKs65732K91j1l+kaSyhdsHV3JY1qA/Imeh01agCP/fAISitqOedv79va9KZLLKF0gZUMm1gwbUQ/nrxsBrUNynf/+r7dUW86zRJKFxQGKgDskpeJehOHpvHcFUeR3iuJ8x9Yykuf7PA6JBOFLKF0QWFJOUPSepCanOB1KMZ0WWb/FJ798VEcmpnG3Cc+4u43P6WxMX5vKzAHzhJKF9gcXibW9E1J4tFLjuDMqcO48/WNXP7YCspr6r0Oy0QJSyidpKoUBSrscpeJOT0S/dx5zqH88vQJvLm+hDPu+Y8N1puQWELppMD+GvbX1NsZiolJIsIlx2Tx6MXTKa2o5fQ/v8fCZVtt9UfTLksonVRgFV4mDhw1egCv/uRYDjuoHzc8u4orn/iQvZV2Z71pnSWUTmqq8Bo10C55mdg2sE8PHr34CK6fNY5/rdnJSXe+zUuf7LCzFfM1llA6qbCknJQkP4P79PA6FGNc5/MJPz5+FC/MPZrBaT2Y+8RHXPrICrbvrfI6NBNBLKF0UtGuCkZl9ELEJoU08WPi0DSev+Jofn7qON4rCHDCHW9xx2sbrBLMAJZQOq2wpNwqvExcSvD7uOwbo3jjmuOYNWkwf/l3Acff/hYP/3cz1XUNXodnPGQJpROqahvYvrfKBuRNXBveL4U/zZnKc1ccRdaAFH6dt4ZjblvCX98qZF91ndfhGQ9YQumEol1W4WVMk6kj+rHoR0ey8LIZjB/Sh9teXc8Rt7zJtU9/TP7mUhu8jyM2Z0gnWIWXMV8lIszITmdGdjqrt5fx+NIt5K3cweIVxYzon8JJ4wdx8oRBHD6yHwl++3dsd1NVGhqV+sbgnw2qpCYlhH1hQEsonVAUKEcERqZbQjGmpUnD0vjdWZO58bQJ/POTz3hl9Wc8tnQLD/1nEylJfiYPT2PqiH5MGprGiP4pjOifQlpKYqc/r9H5gWxo9mPZ2PzHs9mj+bZG/fJ1oyr1DV/u39DYSEMjX/xZ39j41b5a+wxVGhq+jKW+sf02X7zX5n6NNDZ9tvJF+y/eU+e9hq8e/9c+V5XWThLf/OlxYb/KYgmlEwoDFWT2S6FHot/rUIyJWKnJCZxzeCbnHJ5JRU0972wMsHRTKR9t3cP97xRR32ziyR6JPlKTEuiZ5Cc5wffFj2Vjix/z5j+WTQkhEq+oiUCCT/D7BL84fzZ/iODzyZdtfILf5yPB12y7CD4fpCQk4PMJfuGLNn5fi/1F8PuDr33ibPd/+dk+58+EZtv6pySF/bhdTSgiMgv4E+AHHlDVW1u8nww8AhwG7AbOVdXNznvzgEuABuAqVX2tvT5FJAtYCKQDK4ALVNWVW3rHDe7N8H493ejamJiUmpzAKYcM4ZRDhgBQXdfApl0VbC2tZFtpJTv3VVNZ20BVbQM19Y1f/Mi29uPY/Ee46Qe46Qe65ftftJHgj6lPvrrtyzY+fD7wi5Dg930lETTt17Lf5j/kX0kaTizxSNwaMBMRP7AROBkoBpYD56nq2mZtrgAmq+rlIjIHOFNVzxWRCcCTwHRgKPAGcLCzW6t9isgi4FlVXSgifwM+VtW/thdjTk6O5ufnh/GojTEm9onIClXNabndzdGx6UCBqhY5ZwoLgdwWbXKBh53ni4ETJXinYC6wUFVrVHUTUOD012qfzj4nOH3g9HmGi8dmjDGmBTcTyjBgW7PXxc62Vtuoaj1QRvCSVVv7trU9Hdjr9NHWZwEgIpeJSL6I5AcCgU4cljHGmNbEXf2eqi5Q1RxVzcnIyPA6HGOMiRluJpTtQGaz18Odba22EZEEII3g4Hxb+7a1fTfQ1+mjrc8yxhjjIjcTynJgjIhkiUgSMAfIa9EmD7jQeT4bWKLBKoE8YI6IJDvVW2OAZW316ezzb6cPnD5fcPHYjDHGtOBa2bCq1ovIXOA1giW+D6nqGhGZD+Srah7wIPCoiBQApQQTBE67RcBaoB64UlUbAFrr0/nI64GFIvJ/wEdO38YYY7qJa2XD0cDKho0x5sB5UTZsjDEmjsT1GYqIBIAtndx9ALArjOFEi3g87ng8ZojP47ZjDs1Bqvq1Mtm4TihdISL5rZ3yxbp4PO54PGaIz+O2Y+4au+RljDEmLCyhGGOMCQtLKJ23wOsAPBKPxx2Pxwzxedx2zF1gYyjGGGPCws5QjDHGhIUlFGOMMWFhCaUTRGSWiGwQkQIRucHreNwgIpki8m8RWSsia0TkJ872/iLyuoh86vzZz+tYw01E/CLykYi85LzOEpGlzvf9lDOPXEwRkb4islhE1ovIOhE5Mta/axH5f85/26tF5EkR6RGL37WIPCQiJSKyutm2Vr9bCbrbOf5PRGTagXyWJZQD5KxEeQ9wCjABOM9ZYTLW1AM/VdUJwAzgSuc4bwDeVNUxwJvO61jzE2Bds9e3AXep6mhgD8GlqWPNn4BXVXUccCjB44/Z71pEhgFXATmqOong3IBziM3v+h/ArBbb2vpuTyE4Ge8Y4DKg3VVvW7KEcuBCWYky6qnqZ6r6ofN8P8EfmGF8dZXNmFsZU0SGA6cBDzivY341UBFJA76BM6Gqqtaq6l5i/LsmODluT2fZixTgM2Lwu1bVdwhOvttcW99tLvCIBn1AcFmQIaF+liWUAxfKSpQxRURGAlOBpcAgVf3MeetzYJBHYbnlj8B1QKPzOuTVQKNYFhAA/u5c6ntARFKJ4e9aVbcDdwBbCSaSMmAFsf9dN2nru+3S75slFNMuEekFPANcrar7mr/nrEMTM3XnInI6UKKqK7yOpZslANOAv6rqVKCCFpe3YvC77kfwX+NZwFAgla9fFooL4fxuLaEcuFBWoowJIpJIMJk8rqrPOpt3Np0CO3+WeBWfC44GviMimwleyjyB4NhCrK8GWgwUq+pS5/Viggkmlr/rk4BNqhpQ1TrgWYLff6x/103a+m679PtmCeXAhbISZdRzxg4eBNap6p3N3mq+ymZMrYypqvNUdbiqjiT4vS5R1f8hxlcDVdXPgW0iMtbZdCLBxe1i9rsmeKlrhoikOP+tNx1zTH/XzbT13eYB33eqvWYAZc0ujXXI7pTvBBE5leC19qZVI2/xOKSwE5FjgHeBVXw5nvBzguMoi4ARBKf+P0dVWw74RT0ROR64VlVPF5Fsgmcs/QmuBnq+qtZ4GV+4icgUgoUISUARcBHBf3DG7HctIjcD5xKsaPwI+CHB8YKY+q5F5EngeILT1O8Efg08TyvfrZNc/0Lw8l8lcJGqhrwKoSUUY4wxYWGXvIwxxoSFJRRjjDFhYQnFGGNMWFhCMcYYExaWUIwxxoSFJRRjopSIHN80I7IxkcASijHGmLCwhGKMy0TkfBFZJiIrReQ+Z72VchG5y1mP400RyXDaThGRD5y1KJ5rtk7FaBF5Q0Q+FpEPRWSU032vZuuYPO7cmGaMJyyhGOMiERlP8G7so1V1CtAA/A/ByQjzVXUi8DbBu5cBHgGuV9XJBGcpaNr+OHCPqh4KHEVwhlwIzgJ9NcG1ebIJzkdljCcSOm5ijOmCE4HDgOXOyUNPghPxNQJPOW0eA5511iXpq6pvO9sfBp4Wkd7AMFV9DkBVqwGc/paparHzeiUwEnjP/cMy5ussoRjjLgEeVtV5X9ko8ssW7To7B1LzeaYasP+njYfskpcx7noTmC0iA+GLtbwPIvj/XtOstt8D3lPVMmCPiBzrbL8AeNtZMbNYRM5w+kgWkZRuPQpjQmD/mjHGRaq6VkRuBP4lIj6gDriS4CJW0533SgiOs0BwKvG/OQmjadZfCCaX+0RkvtPH2d14GMaExGYbNsYDIlKuqr28jsOYcLJLXsYYY8LCzlCMMcaEhZ2hGGOMCQtLKMYYY8LCEooxxpiwsIRijDEmLCyhGGOMCYv/DxsS93RWtV+NAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SpaqsL4S_D_z"
      },
      "source": [
        "## 5.2 model準備\n",
        "訓練するmodelを構築する関数を定義します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mcnldhvHc54M"
      },
      "source": [
        "def get_pretrained_model():\n",
        "    \"\"\"\n",
        "    使用する事前学習されたmodelを取得する。\n",
        "    \"\"\"\n",
        "    if Config.model==\"efn_b4\":\n",
        "        pretrained_model = efn.EfficientNetB4(\n",
        "            weights=Config.weights, \n",
        "            include_top=False)\n",
        "        \n",
        "    elif Config.model==\"efn_b7\":\n",
        "        pretrained_model = efn.EfficientNetB7(\n",
        "            weights=Config.weights, \n",
        "            include_top=False)\n",
        "    \n",
        "    elif \"v2\" in Config.model:\n",
        "        pretrained_model = hub.KerasLayer(hub_url)\n",
        "\n",
        "    pretrained_model.trainable = True\n",
        "\n",
        "    return pretrained_model\n",
        "\n",
        "\n",
        "def build_model():\n",
        "    \"\"\"\n",
        "    modelの全体構造を定義する。\n",
        "    \"\"\"\n",
        "    pretrained_model = get_pretrained_model()\n",
        "    \n",
        "    input = tf.keras.layers.Input(shape=(Config.image_size, Config.image_size, 3))\n",
        "    x = pretrained_model(input)\n",
        "    if \"v2\" not in Config.model:\n",
        "        x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "    elif \"v2\" in Config.model:\n",
        "        x = tf.keras.layers.Dropout(rate=0.2)(x)\n",
        "    pred = tf.keras.layers.Dense(Config.n_classes, activation='softmax')(x)\n",
        "\n",
        "    model = tf.keras.models.Model(inputs=input, outputs=pred)\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(), \n",
        "                  loss=categorical_focal_loss(alpha=1), \n",
        "                  metrics=['accuracy'])\n",
        "    \n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1X2fLk4nJa-Q"
      },
      "source": [
        "def get_model():\n",
        "    \"\"\"\n",
        "    modelを実行環境下で取得する。\n",
        "    \"\"\"\n",
        "    if TPU:\n",
        "        tf.config.experimental_connect_to_cluster(TPU)\n",
        "        tf.tpu.experimental.initialize_tpu_system(TPU)\n",
        "        tpu_strategy = tf.distribute.TPUStrategy(TPU)\n",
        "        with tpu_strategy.scope():\n",
        "            model = build_model()\n",
        "    else:\n",
        "        model = build_model()\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0-wQbiVPRwFc"
      },
      "source": [
        "## 5.3 訓練関数\n",
        "訓練の手順を定義します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RIJJZ4q7Oyl4"
      },
      "source": [
        "def train_cv():\n",
        "    \"\"\"\n",
        "    交差検証関数(訓練)\n",
        "    \"\"\"\n",
        "    # 訓練状況を記録するdictionary\n",
        "    try:\n",
        "        # 訓練途中であれば引継ぐ\n",
        "        with open(os.path.join(MODEL, \"status.json\"), mode=\"r\") as f:\n",
        "            status = json.load(f)       \n",
        "    except:\n",
        "        # 新規作成\n",
        "        time_jp = datetime.datetime.now() + datetime.timedelta(hours=9)\n",
        "        time_jp = time_jp.strftime(\"%m%d%H%M\")\n",
        "        status = {\"fold\": [],\n",
        "                  \"seed\": Config.seed,\n",
        "                  \"time_jp\": time_jp,\n",
        "                  \"model_path\" : [],\n",
        "                  \"model_name\" : Config.model,\n",
        "                  \"image_size\" : Config.image_size,\n",
        "                  \"val_accuracy\": [],\n",
        "                  \"val_loss\": []}\n",
        "    \n",
        "    # 訓練ファイルのpathとラベルを取得\n",
        "    filepaths, labels = get_train_data()\n",
        "\n",
        "    # 交差検証\n",
        "    for i_fold, (tr_idx, val_idx) in enumerate(skf(filepaths, np.argmax(labels, axis=1))):\n",
        "        K.clear_session()\n",
        "        \n",
        "        print(f\"\\n##### FOLD {i_fold+1} #####\\n\")\n",
        "        model_name = f\"model{status['time_jp']}_fold{i_fold+1}\"\n",
        "        model_path = os.path.join(MODEL, f\"{model_name}.h5\")\n",
        "\n",
        "        # 保存したモデルがある場合訓練をスキップ\n",
        "        if os.path.exists(model_path):\n",
        "            continue\n",
        "\n",
        "\n",
        "        # 少ないラベルのデータ複製\n",
        "        if Config.copy:\n",
        "            tr_idx = copy_few_data(tr_idx, labels)\n",
        "\n",
        "        tr_filepaths, tr_labels = filepaths[tr_idx], labels[tr_idx]\n",
        "        val_filepaths, val_labels = filepaths[val_idx], labels[val_idx]\n",
        "        \n",
        "        # 訓練データに擬似ラベルデータを加える\n",
        "        if Config.pseudo:\n",
        "            tr_filepaths, tr_labels = concat_pseudo(tr_filepaths, tr_labels)\n",
        "\n",
        "        # callbacks\n",
        "        checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\n",
        "            filepath=model_path, \n",
        "            monitor=Config.best_monitor, \n",
        "            verbose=1, \n",
        "            save_best_only=True, \n",
        "            save_weights_only=True\n",
        "            )\n",
        "        stop_cb = tf.keras.callbacks.EarlyStopping(\n",
        "            monitor=Config.stop_monitor, \n",
        "            patience=Config.patience, \n",
        "            verbose=1, \n",
        "            mode='auto'\n",
        "            )\n",
        "        lr_cb = tf.keras.callbacks.LearningRateScheduler(\n",
        "            lr_schedule, \n",
        "            verbose=True\n",
        "            )\n",
        "\n",
        "        # tf.data.Dataset準備\n",
        "        image_processor = ImageProcessor(Config.num_ops, \n",
        "                                         Config.magnitude, \n",
        "                                         Config.image_size)\n",
        "        tr_ds = image_processor.rand_aug_dataset(tr_filepaths, \n",
        "                                                 tr_labels)\n",
        "        val_ds = image_processor.val_dataset(val_filepaths, \n",
        "                                             val_labels) \n",
        "\n",
        "        # 訓練実行\n",
        "        model = get_model()\n",
        "        history = model.fit(\n",
        "            tr_ds,\n",
        "            validation_data=val_ds,\n",
        "            steps_per_epoch=len(tr_idx)//Config.batch_size,\n",
        "            validation_steps=len(val_idx)//Config.batch_size,\n",
        "            epochs=Config.epochs,\n",
        "            verbose=1,\n",
        "            callbacks=[stop_cb, lr_cb, checkpoint_cb]\n",
        "            )\n",
        "        \n",
        "        # fold毎の記録\n",
        "        history_df = pd.DataFrame(history.history)\n",
        "        history_df.to_csv(os.path.join(MODEL, f\"history-{model_name}.csv\"), \n",
        "                          index=False)\n",
        "\n",
        "        status[\"val_accuracy\"].append(max(history.history['val_accuracy']))\n",
        "        status[\"val_loss\"].append(min(history.history['val_loss']))\n",
        "        status[\"fold\"].append(i_fold)\n",
        "        status[\"model_path\"].append(model_path)\n",
        "\n",
        "        print(f\"\\n{status}\\n\")\n",
        "        with open(os.path.join(MODEL, \"status.json\"), mode=\"w\") as f:\n",
        "            json.dump(status, f)\n",
        "\n",
        "    return status"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nPAbv1_oU1fs"
      },
      "source": [
        "## 5.4 記録\n",
        "学習結果を記録し、json形式で保存します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pGYNPyEH9YGd"
      },
      "source": [
        "def record_total_result(status):\n",
        "    \"\"\"\n",
        "    訓練全体の結果とハイパーパラメータとモデルの構造を記録する。\n",
        "    \"\"\"\n",
        "    val_acc_list = status[\"val_accuracy\"]\n",
        "    val_loss_list = status[\"val_loss\"]\n",
        "    time_jp = status[\"time_jp\"]\n",
        "    model_path = status[\"model_path\"]\n",
        "  \n",
        "    # 訓練が完了した場合、dictionaryを個別化して保存\n",
        "    with open(os.path.join(RECORD, f\"record{time_jp}.json\"), mode=\"w\") as f:\n",
        "        json.dump(status, f)\n",
        "\n",
        "    # notebookのコードを呼び出す\n",
        "    with open(os.path.join(DRIVE, \"religious_art_train.ipynb\"), \"r\") as f:\n",
        "        code = f.read()\n",
        "\n",
        "    # ハイパーパラメータとモデル構造のセルを抽出し記録\n",
        "    code_text = \"\"\n",
        "    for i in [14, 31]:\n",
        "        code_text += \"\".join(json.loads(code)[\"cells\"][i][\"source\"])+\"\\n\\n\\n\"\n",
        "\n",
        "    with open(os.path.join(MODEL, f\"model{time_jp}conf_result.txt\"), \"w\") as f:\n",
        "        f.write(\n",
        "            f\"{model_path}\\n\"\n",
        "            f\"seed : {Config.seed}\\n\"\n",
        "            f\"val acc: {val_acc_list},\\n mean: {np.mean(val_acc_list)}\\n\"\n",
        "            f\"val loss: {val_loss_list},\\n mean: {np.mean(val_loss_list)}\\n\"\n",
        "            f\"CODE: \\n{code_text}\"\n",
        "            )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ENtOyP15ma62"
      },
      "source": [
        "# 6.実行"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KM-jbmAyJuIT"
      },
      "source": [
        "def main():\n",
        "    status = train_cv()\n",
        "    record_total_result(status)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dK0CwIH8bve0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c28b0f23-beae-48de-a523-40268aa44e8d"
      },
      "source": [
        "main()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "##### FOLD 1 #####\n",
            "\n",
            "INFO:tensorflow:Deallocate tpu buffers before initializing tpu system.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Deallocate tpu buffers before initializing tpu system.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.124.17.242:8470\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.124.17.242:8470\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://github.com/qubvel/efficientnet/releases/download/v0.0.1/efficientnet-b7_noisy-student_notop.h5\n",
            "258072576/258068648 [==============================] - 2s 0us/step\n",
            "258080768/258068648 [==============================] - 2s 0us/step\n",
            "\n",
            "Epoch 00001: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 1/2\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:2970: StrategyBase.unwrap (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "use `experimental_local_results` instead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:2970: StrategyBase.unwrap (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "use `experimental_local_results` instead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20/20 [==============================] - ETA: 0s - loss: 2.1921 - accuracy: 0.0969\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.07187, saving model to /content/drive/MyDrive/portforio/religious_art/model/efn_b7-600/model11141537_fold1.h5\n",
            "20/20 [==============================] - 282s 3s/step - loss: 2.1921 - accuracy: 0.0969 - val_loss: 2.2098 - val_accuracy: 0.0719 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 00002: LearningRateScheduler setting learning rate to 7.9e-05.\n",
            "Epoch 2/2\n",
            "20/20 [==============================] - ETA: 0s - loss: 2.1452 - accuracy: 0.1406\n",
            "Epoch 00002: val_accuracy improved from 0.07187 to 0.09063, saving model to /content/drive/MyDrive/portforio/religious_art/model/efn_b7-600/model11141537_fold1.h5\n",
            "20/20 [==============================] - 24s 1s/step - loss: 2.1452 - accuracy: 0.1406 - val_loss: 2.2131 - val_accuracy: 0.0906 - lr: 7.9000e-05\n",
            "\n",
            "{'fold': [0], 'seed': 21, 'time_jp': '11141537', 'model_path': ['/content/drive/MyDrive/portforio/religious_art/model/efn_b7-600/model11141537_fold1.h5'], 'val_accuracy': [0.09062500298023224], 'val_loss': [2.2098100185394287]}\n",
            "\n",
            "\n",
            "##### FOLD 2 #####\n",
            "\n",
            "INFO:tensorflow:Deallocate tpu buffers before initializing tpu system.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Deallocate tpu buffers before initializing tpu system.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.124.17.242:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.124.17.242:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.124.17.242:8470\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.124.17.242:8470\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 00001: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 1/2\n",
            "21/21 [==============================] - ETA: 0s - loss: 2.2514 - accuracy: 0.0595\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.07812, saving model to /content/drive/MyDrive/portforio/religious_art/model/efn_b7-600/model11141537_fold2.h5\n",
            "21/21 [==============================] - 279s 2s/step - loss: 2.2514 - accuracy: 0.0595 - val_loss: 2.2070 - val_accuracy: 0.0781 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 00002: LearningRateScheduler setting learning rate to 7.9e-05.\n",
            "Epoch 2/2\n",
            "21/21 [==============================] - ETA: 0s - loss: 2.1715 - accuracy: 0.1280\n",
            "Epoch 00002: val_accuracy did not improve from 0.07812\n",
            "21/21 [==============================] - 18s 860ms/step - loss: 2.1715 - accuracy: 0.1280 - val_loss: 2.1990 - val_accuracy: 0.0531 - lr: 7.9000e-05\n",
            "\n",
            "{'fold': [0, 1], 'seed': 21, 'time_jp': '11141537', 'model_path': ['/content/drive/MyDrive/portforio/religious_art/model/efn_b7-600/model11141537_fold1.h5', '/content/drive/MyDrive/portforio/religious_art/model/efn_b7-600/model11141537_fold2.h5'], 'val_accuracy': [0.09062500298023224, 0.078125], 'val_loss': [2.2098100185394287, 2.1989834308624268]}\n",
            "\n"
          ]
        }
      ]
    }
  ]
}